---
layout: default
title: Welcome
author: Danishjeet Singh

---

<!-- <div style="background-color: #f4f4f4; color: #333; text-align: center; padding: 20px; font-size: 24px; font-weight: bold; border: 2px solid #ccc;">
    I am actively applying to CS PhD programs!
</div>
<br> -->
Hi, just call me Danish(daa-nish)

I can be best reached through my email or my LinkedIn.

I'm a first year Computer Science PhD Student at Indiana University.

I obtained my undergraduate degree from IU as well and was very fortunate to be advised by 
[Dr. Filippo Menczer ](https://cnets.indiana.edu/fil) at 
[Observatory On Social Media at Indiana Univeristy(OSoMe@IU)](https://osome.iu.edu/). 
Previously I've also worked with [Dr. David Crandall](https://homes.luddy.indiana.edu/djcran/) 
at the [IU Computer Vision Lab](http://vision.soic.indiana.edu/).

I’m broadly fascinated by <strong>Generative AI</strong>, both how people use it and the pitfalls it can create, and I’m committed to digging into this technology at a deeper level to build <strong>customizable</strong>, <strong>explainable systems</strong>. From a <strong>computational social science</strong> perspective, I study the <strong>societal harms</strong> of generative models like <strong>deepfakes</strong> and <strong>toxic content</strong> on social platforms. On the <strong>mechanistic</strong> side, I probe <strong>vision-language models</strong> for <strong>object hallucination</strong> and <strong>concept evolution</strong>. Ultimately, I want to bridge both worlds: understanding the social issues these tools raise and uncovering their inner workings so we can design <strong>safer</strong>, more <strong>transparent AI</strong>.


<!-- I am broadly interested in computational social science and multimodal machine learning. My research has focused on deepfake detection, hate speech on social media platforms, and political communication online. Currently, I am exploring vision-language alignment and visual grounding, with a particular interest in spatial reasoning tasks. I am also interested in inference-based approaches for guiding vision-language models in latent space to improve consistency and reduce hallucinations. -->

<!-- I write sometimes, checkout my [Medium](https://singhdan.medium.com/) page. -->

## Publications and Pre-prints
[Prefilled responses enhance zero-shot detection of AI-generated images](https://arxiv.org/abs/2506.11031) (2025)
<br> *Kachwala, Z., <strong>Danishjeet Singh</strong>, Yang, D., & Menczer, F.*
<br> arxiv preprint <br> 
<strong>TLDR;</strong> We show that prefilling Vision-Language Model responses with "Let's examine the style and synthesis artifacts" boosts AI-generated image detection by up to 24% without any training. This simple technique generalizes across 16 different image generators and outperforms standard prompting methods—basically, we guide the model to focus on the right visual cues by starting its response for it.


[Characteristics and prevalence of fake social media profiles with AI-generated faces](https://doi.org/10.54501/jots.v2i4.197) (2024)
<br> *Yang, K.C., <strong>Danishjeet Singh</strong> & Menczer, F.*
<br> Published in the [Journal of Online Trust and Safety](https://tsjournal.org/index.php/jots).<br>
<strong>TLDR;</strong> A tiny fraction of Twitter profiles use AI‑generated face photos, yet those accounts often disseminate scams and spam; by noting that such fake faces have their eyes in exactly the same place, we could identify them and estimated about 10,000 active accounts of this type.

{% include news-feed.html %}

<!-- <span style="font-size:18px;">[Blog](./blog.html)</span> for weekend projects and some deep knowledge work -->
<span style="font-size:18px;">[Projects](./projects.html)</span> for creative and serious work!!

<span style="font-size:18px;">[Tools & Software](./tools.html)</span> that some may find helpful.

<span style="font-size:18px;">[Miscellaneous](./misc.html)</span> shenanigans basically
