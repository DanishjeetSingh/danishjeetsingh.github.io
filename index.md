---
layout: default
title: Welcome
author: Danishjeet Singh

---

<!-- <div style="background-color: #f4f4f4; color: #333; text-align: center; padding: 20px; font-size: 24px; font-weight: bold; border: 2px solid #ccc;">
    I am actively applying to CS PhD programs!
</div>
<br> -->
Hi, just call me Danish(daa-nish)

I can be best reached through my email or my LinkedIn.

I'm a first year Computer Science PhD Student at Indiana University, advised by [Dr. Mary Jean Amon](https://scholar.google.com/citations?hl=en&user=1OBLAFoAAAAJ&view_op=list_works&sortby=pubdate).

I obtained my undergraduate degree from IU as well and was very fortunate to be advised by 
[Dr. Filippo Menczer ](https://cnets.indiana.edu/fil) at 
[Observatory On Social Media at Indiana Univeristy(OSoMe@IU)](https://osome.iu.edu/). 
Previously I've also worked with [Dr. David Crandall](https://homes.luddy.indiana.edu/djcran/) 
at the [IU Computer Vision Lab](http://vision.soic.indiana.edu/).

I’m broadly fascinated by <strong>Generative AI</strong>, both how people use it and the pitfalls it can create, and I’m committed to digging into this technology at a deeper level to build <strong>customizable</strong>, <strong>explainable systems</strong>. From a <strong>computational social science</strong> perspective, I study the <strong>societal harms</strong> of generative models like <strong>deepfakes</strong> and <strong>toxic content</strong> on social platforms. On the <strong>mechanistic</strong> side, I probe <strong>vision-language models</strong> for <strong>object hallucination</strong> and <strong>concept evolution</strong>. Ultimately, I want to bridge both worlds: understanding the social issues these tools raise and uncovering their inner workings so we can design <strong>safer</strong>, more <strong>transparent AI</strong>.


<!-- I am broadly interested in computational social science and multimodal machine learning. My research has focused on deepfake detection, hate speech on social media platforms, and political communication online. Currently, I am exploring vision-language alignment and visual grounding, with a particular interest in spatial reasoning tasks. I am also interested in inference-based approaches for guiding vision-language models in latent space to improve consistency and reduce hallucinations. -->

<!-- I write sometimes, checkout my [Medium](https://singhdan.medium.com/) page. -->

## Publications and Pre-prints
[Task-aligned prompting improves zero-shot detection of AI-generated images by Vision-Language Models](https://arxiv.org/abs/2506.11031) (2025)
<br> *Kachwala, Z., <strong>Danishjeet Singh</strong>, Yang, D., & Menczer, F.*
<br> arxiv preprint <br> 
<strong>TLDR;</strong> Simply prefacing the AI’s response with “Let’s examine the style and the synthesis artifacts” makes vision‑language models 8 %–29 % more accurate at spotting AI-generated pictures compared with the same models used off‑the‑shelf or with generic chain‑of‑thought prompts


[Characteristics and prevalence of fake social media profiles with AI-generated faces](https://doi.org/10.54501/jots.v2i4.197) (2024)
<br> *Yang, K.C., <strong>Danishjeet Singh</strong> & Menczer, F.*
<br> Published in the [Journal of Online Trust and Safety](https://tsjournal.org/index.php/jots).<br>
<strong>TLDR;</strong> A tiny fraction of Twitter profiles use AI‑generated face photos, yet those accounts often disseminate scams and spam; by noting that such fake faces have their eyes in exactly the same place, we could identify them and estimated about 10,000 active accounts of this type.

{% include news-feed.html %}

<!-- <span style="font-size:18px;">[Blog](./blog.html)</span> for weekend projects and some deep knowledge work -->
<span style="font-size:18px;">[Projects](./projects.html)</span> for creative and serious work!!

<span style="font-size:18px;">[Tools & Software](./tools.html)</span> that some may find helpful.

<span style="font-size:18px;">[Miscellaneous](./misc.html)</span> shenanigans basically
